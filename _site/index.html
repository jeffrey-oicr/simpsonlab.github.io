<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Simpson Lab Blog &middot; SimpsonLab blog
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Simpson Lab Blog
        </a>
      </h1>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/archive/">Archive</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      

    </nav>

    <p>&copy; 2016. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
    
  
    
      <div class="post">
        <h1 class="post-title">
          <a href="/2016/02/03/ebola-snps/">
            Finding Ebola SNPs
          </a>
        </h1>

        <span class="post-date">03 Feb 2016</span>

        <p>Today Nature published our <a href="http://dx.doi.org/10.1038/nature16996">paper</a> describing the use of the Oxford Nanopore MinION to track the Ebola outbreak in West Africa. Over on Nick Loman’s <a href="http://lab.loman.net/2016/02/03/behind-the-paper-real-time-portable-sequencing-for-ebola-surveillance/">blog</a> you can read an excellent account of how this project started and progressed. For my part, I worked on the method that we used to call SNPs from the sequenced Ebola samples, which I’ll describe in this post.</p>

<h2 id="background">Background</h2>

<p>Nanopore sequencing measures the changes in electric current (termed <em>events</em>) caused by DNA translocating through the pore. Previously I developed a hidden Markov model for calculating the probability of observing a particular sequence of events given a DNA sequence. We’ve described this HMM in our genome assembly <a href="http://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3444.html">paper</a> and in previous blog posts <a href="http://simpsonlab.github.io/2015/03/30/optimizing-hmm/">here</a> and <a href="http://simpsonlab.github.io/2015/04/08/eventalign/">here</a>. I won’t describe the details again but the important thing to understand for this post is that we have a function <script type="math/tex">P(D \; \vert \; S)</script> that calculates the probability of observing some data <script type="math/tex">D</script> (measured by the nanopore sequencer) given a sequence <script type="math/tex">S</script> (that we want to determine).  In our genome assembly paper we used the HMM to optimize a consensus sequence by iteratively editing <script type="math/tex">S</script> until we couldn’t make any further improvements.</p>

<h2 id="the-first-algorithm">The first algorithm</h2>

<p>Last summer Nick and Matt Loose organized a hackathon in Birmingham where I started to work on the SNP calling problem. I thought this would be straightforward as SNP calling is a special case of calculating a consensus sequence. If SNPs are well-separated from each other we can simply calculate the likelihood of a haplotype containing a SNP and compare it to the likelihood of the reference haplotype:</p>

<p><script type="math/tex">P(D \; \vert \; \texttt{...ACGATCGTACA...})</script> (reference)<br />
<script type="math/tex">P(D \; \vert \; \texttt{...ACGATAGTACA...})</script> (snp haplotype)</p>

<p>If <script type="math/tex">P(D \; \vert \; \texttt{...ACGATAGTACA...}) > P(D \; \vert \; \texttt{...ACGATCGTACA...})</script> we would call a C to A SNP  and output it in a VCF file with a corresponding quality score. This simple approach worked well for most SNPs in our test case. We observed however that we would miscall regions that had multiple nearby SNPs. Recall from the previous posts that the nanopore sequencer does not measure signals from individual bases; it effectively reads k-mers, not bases. When trying to call nearby SNPs unless we present the complete true haplotype sequence to the algorithm it may either only find a subset of the true SNPs or worse, make false calls. Clearly we had to jointly test SNPs in groups rather than individually.</p>

<h2 id="the-failed-algorithm">The failed algorithm</h2>

<p>I spent the remainder of the hackathon working on an idea that would more generally solve the consensus problem. Let’s say we know the true sequence of some partial region of the genome, <script type="math/tex">S’</script>. Can we determine the base immediately following <script type="math/tex">S'</script>? On the surface this is simple: we can select the extension with the greatest likelihood out of the four possibilities:</p>

<p><script type="math/tex">P(D \; \vert \; \texttt{S'A})</script><br />
<script type="math/tex">P(D \; \vert \; \texttt{S'C})</script><br />
<script type="math/tex">P(D \; \vert \; \texttt{S'G})</script><br />
<script type="math/tex">P(D \; \vert \; \texttt{S'T})</script></p>

<p>To do this calculation we need to modify our HMM. Previously we required the event sequence to be completely aligned - we knew the first and last event observation for the region of interest. For this problem, we need to relax this constraint and allow uncertainty about the endpoint of the sequence of events. We modified our HMM to handle this by allowing unmatched events at the beginning and end of the matching region, similar to how bases may be soft-clipped in nucleotide alignments.</p>

<p>With the HMM modified we can calculate likelihoods for the one-base extensions of S’. By iterating the procedure we would hopefully arrive at the true sequence of the region including any variants. Selecting the single best extension at each step worked extremely poorly. If an error was made (the wrong extension was selected) the error would propagate and we would have a nonsense reconstruction of the region. I tried various heuristics for keeping track of the N best solutions to avoid forcing the algorithm to take a single choice. This can be incredibly expensive however and I did not find a solution that worked well in all cases. When this algorithm goes wrong we would get a dense cluster of false positive SNPs, which is not a good property of an algorithm. I abandoned this approach shortly after I left the hackathon.</p>

<h2 id="the-final-algorithm">The final algorithm</h2>

<p>The iterative algorithm which performed reasonably well, but not perfectly, for variant calling ignores an additional source of information: the basecalled sequences of the reads. We decided to find candidate SNPs from the nanopore reads aligned to the reference genome and test combinations of these candidates. We batch SNPs into clusters that are separated by about 10bp, a value I determined that allows the clusters to be treated independently. We then simply generate all possible haplotypes (<script type="math/tex">2^n</script> for <script type="math/tex">n</script> SNPs) and calculate the likelihood for each haplotype using the HMM. The haplotype with the greatest likelihood is selected as the sequence for the region and its set of SNPs is output in the VCF file.</p>

<p>I sent this version of the algorithm to Nick who tested it on the Mayinga strain of Ebola which has ~500 mutations when compared to the Makona reference (in 19,000 bases, i.e. &gt;2.6% divergence - samples from the West Africa outbreak typically have 20-40 SNPs and are much easier to call). This haplotype-based version was far better than the previous algorithms and forms the basis of the method we used in the paper.</p>

<p>We made a final improvement which used a new 6-mer pore model from Oxford Nanopore. To use this model on our data, which was sequenced with the older SQK005 sequencing kit (and basecalled using 5-mers), we had to calculate a new scaling parameter to transform the events to the 6-mer model. Using 6-mers was more accurate in difficult sequence contexts and completed the algorithm development. The calls from this algorithm are presented in the paper. The SNP caller is implemented in the new “variants” module of <a href="https://github.com/jts/nanopolish">nanopolish</a>.</p>

      </div>
    
  
    
      <div class="post">
        <h1 class="post-title">
          <a href="/2015/12/18/kdtree-mapping/">
            Approximate Mapping of Nanopore Squiggle Data with Spatial Indexing
          </a>
        </h1>

        <span class="post-date">18 Dec 2015</span>

        <h3 id="nanopore-data">Nanopore data</h3>

<p>Here at the Simpsonlab we work with signal-level data from nanopore
sequencers, particularly those from ONT like the MinION.  Signal-level
data looks something like this:</p>

<p><img src="/assets/kdtreemapping/squiggle.png" alt="Idealized Example Squiggle Plot" /></p>

<p>where the data comes in as a stream of events (the red lines) with
means, standard deviations, and durations, with each black point
being an individual signal reading.  We use the signal-level data
partly for accuracy - because converting each red line and dozens
of black points into one of four letters invariably loses lots
of information - and partly because those basecalls might not be
available in, say, the field, where the portability of the nanopore
sequencers really shines.</p>

<p>This data has to be interpreted in terms of a particular model of
the interaction of the pore and the strand of DNA; such a pore model
gives, amongst other things, an expected signal mean and standard
deviation for currents through the pore when a given <script type="math/tex">k</script>mer is in
the pore (for the MinION devices, pore models typically use <script type="math/tex">k</script>=5 or
6).  So a pore model might be, for <script type="math/tex">k</script>=5, a table with 1024 entries
that looks something like this:</p>

<table>
  <thead>
    <tr>
      <th>kmer</th>
      <th>mean</th>
      <th>std dev</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>AAAAA</td>
      <td>70.24</td>
      <td>± 0.95 pA</td>
    </tr>
    <tr>
      <td>AAAAC</td>
      <td>66.13</td>
      <td>± 0.75 pA</td>
    </tr>
    <tr>
      <td>AAAAG</td>
      <td>70.23</td>
      <td>± 0.76 pA</td>
    </tr>
    <tr>
      <td>AAAAT</td>
      <td>69.25</td>
      <td>± 0.68 pA</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
      <td>…</td>
    </tr>
  </tbody>
</table>

<p>and using such a pore model it’s fairly straightforward to
go from a sequence to an expected set of signal levels from the
sequencer: so, say, for the 10-base sequence AAAAACGTCC and the
above 5-mer pore model we’d expect 6 events (10-5+1) that look like:</p>

<table>
  <thead>
    <tr>
      <th>event</th>
      <th>kmer</th>
      <th>mean</th>
      <th>range (1<script type="math/tex">\sigma</script>)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>e1</em></td>
      <td>AAAAA</td>
      <td>70.2 pA</td>
      <td>69.3 -  71.2 pA</td>
    </tr>
    <tr>
      <td><em>e2</em></td>
      <td>AAAAC</td>
      <td>66.1 pA</td>
      <td>65.4 -  66.9 pA</td>
    </tr>
    <tr>
      <td><em>e3</em></td>
      <td>AAACG</td>
      <td>62.8 pA</td>
      <td>62.0 -  63.6 pA</td>
    </tr>
    <tr>
      <td><em>e4</em></td>
      <td>AACGT</td>
      <td>67.6 pA</td>
      <td>66.3 -  68.9 pA</td>
    </tr>
    <tr>
      <td><em>e5</em></td>
      <td>ACGTC</td>
      <td>56.6 pA</td>
      <td>54.5 -  58.7 pA</td>
    </tr>
    <tr>
      <td><em>e6</em></td>
      <td>CGTCC</td>
      <td>49.9 pA</td>
      <td>49.1 -  50.7 pA</td>
    </tr>
  </tbody>
</table>

<p>Using those models, plus HMMs and a tonne of math, Jared’s
<a href="https://github.com/jts/nanopolish">nanopolish</a> tool has had enormous
success improving the quality of nanopore reads and assemblies of
nanopore data.  As one can see from the ‘range’ column above, and
from the histogram on the side of the first plot, which shows the
numbers of kmers which fall into 1pA bins in the pore model, this
isn’t necessarily particularly easy.  There are over 70 kmers which
are expected to have means in the range 69.5pA - 70.5pA;
that plus the wide standard deviations means that there is enormous
ambiguity going back from signal levels to sequence.</p>

<h3 id="mapping">Mapping</h3>

<p>This ambiguity introduces complication into another part of the
bioinformatics pipeline - mapping.  While several mappers (BWA MEM,
LAST) work quite well with basecalled ONT data, and one mapper<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>
has been written specifically for basecalled ONT data, mapping
signal-level data directly is a little tougher.  It is one thing
for a seed sequence in the read to occur in multiple locations in
the reference index; it is another thing for a sequence of
floating-point currents to plausibly represent one of hundreds of
seed sequences.</p>

<p>On the other hand, a flurry of recent important papers and software<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>
<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup> <sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup> <sup id="fnref:5"><a href="#fn:5" class="footnote">5</a></sup>, the first of which are discussed in some informative
<a href="http://robpatro.com/blog/?p=248">blog</a>
<a href="https://liorpachter.wordpress.com/2015/11/01/what-is-a-read-mapping/">posts</a>,
have demonstrated the usefulness of approximate read mapping.  In
our case, mapping to an approximate region of a reference would
allow exact but computationally expensive methods like <code>nanopolish
eventalign</code> to produce precise alignments, or simple assignment may
be all that is necessary for other applications.</p>

<p>So an output approximate mapping would be valuable, but the issues
remains of how to disambiguate the signal level values.</p>

<h3 id="spatial-indexing">Spatial Indexing</h3>

<p>Importantly, while any individual event is very difficult to assign
with precision, sequences of events are less ambiguous, as any given
event is followed, with high probability, by one of only four other
events.  Thus, by examining tuples of events, one can greatly
increase specificity.</p>

<p>And there are well-developed sets of techniques for looking up lists
of <script type="math/tex">d</script> floating point values to look for candidate matches: <a href="https://en.wikipedia.org/wiki/Spatial_database">spatial
indexes</a>, where
each query or match is considered as a point in <script type="math/tex">d</script>-dimensional
space, and the goal is to return either some number of nearest
points (k-Nearest-Neighbours, or <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">kNN queries</a>), or
all matches within some, typically euclidean, distance.</p>

<p>To see how this would work, consider indexing the sequence above,
AAAAACGTCC, in a spatial index with <script type="math/tex">d=2</script>.  There are a total of 6
events, so we’d have 5 points (6-2+1), each points in 2-dimensional
space; 4 are plotted below (the other falls out of the range of the
plot)</p>

<p><img src="/assets/kdtreemapping/2d-spatial-query.png" alt="2D Spatial Query" style="width: 478px; margin-left:auto; margin-right:auto;" /></p>

<p>and a query for <script type="math/tex">d</script> read events that could be matched by (69.5, 67), the blue point, would return the nearest match (70.2, 66.1) corresponding to the <script type="math/tex">k+d-1</script>-mer AAAAAC.</p>

<p>So to map event data, one can:</p>

<ul>
  <li>Generate an index:
    <ul>
      <li>Generate all overlapping tuples of <script type="math/tex">d</script> kmers from a reference</li>
      <li>Using a pore model, convert those into points in <script type="math/tex">d</script>-space</li>
      <li>Create a spatial index of those points,</li>
    </ul>
  </li>
  <li>For every read:
    <ul>
      <li>Take every overlapping set of <script type="math/tex">d</script> events</li>
      <li>Look it up in a spatial index</li>
      <li>Find a most likely starting point for the read in the reference, with a quality score.</li>
    </ul>
  </li>
</ul>

<p>Note that one has to explicitly index both the forward and reverse
strands of the reference, since you don’t <em>a priori</em> know
what the “reverse complement” of 65.5 pA is.  One
also has to generate multiple indices; for 2D ONT reads, there is
a pore model for the template strand of a read, and typically two
possible models to choose from for the complement strand of a read,
so one needs three indexes in total to query.</p>

<h3 id="what-dimension-to-choose">What dimension to choose?</h3>

<p>To test this approach, you have to choose a <script type="math/tex">d</script> to use.  On the one
hand, you would like to choose as large a dimension as you can; the
larger <script type="math/tex">k+d-1</script> is, the more unique each seed is and the fewer places
it will occur in any reference sequence.</p>

<p>On the other hand, two quite different constraints put a strong upper limit on the dimensions that will be useful:</p>

<ul>
  <li>The <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse of dimensionality</a> -
in high spatial dimensions, nearest-neighbour searching is extremely
inefficient, because distance loses its discriminative power.  (Most
things are roughly equally far from each other in 100-dimensional
space; there are a lot of routes you can take!)  As a practical
matter, for most spatial index implementations, for <script type="math/tex">d > 15-20</script> or
so you might as well just do a linear search over all possible
items;</li>
  <li>Current approaches to segmentation mean that ONT data has very
frequent ‘stops’ and ‘skips’ - that is,
events are spuriously either inserted or deleted from the data.
Exactly as with noisy basecalled sequences, this strongly limits
the length of sequence that can be usefully used as seeds.  As we
see below for one set of <em>E. coli</em> data, there is probably not much
point in using <script type="math/tex">d \ge 10</script> even for template-strand data, as the
median “dmer” will have an insertion/deletion in it.</li>
</ul>

<p><img src="/assets/kdtreemapping/events-per-stopskip.png" alt="Distribution of lengths of continuous move events" style="width: 550px; margin-left:auto; margin-right:auto;" /></p>

<p>For these two reasons, we’ve been playing with <script type="math/tex">d \approx
8</script>.  I’ll note that while increasing <script type="math/tex">d</script> is the most obvious
knob to turn to increase specificity of the match, higher <script type="math/tex">k</script>
helps as well.</p>

<h3 id="normalizing-the-signal-levels">Normalizing the signal levels</h3>

<p>One issue we haven’t mentioned is that the raw nanopore data needs
calibration to be compared to the model; there is an additive shift and drift over time,
and a multiplicative scale that has to be taken into account.</p>

<p>A very simple “methods of moments” calculation works
surprisingly well for long-enough reads, certainly well enough to
start an iterative process; for any given model one is trying to
fit a read to, rescaling the mean and standard deviation of read
events to model events gives a good starting point for calibration,
and drift is initially ignored.</p>

<p><img src="/assets/kdtreemapping/initial-rescale.png" alt="Simple initial rescaling of current values by method of moments" /></p>

<h3 id="proof-of-concept">Proof of concept</h3>

<p>A simple proof of concept of using spatial indexing to approximately map squiggle data can be found <a href="https://github.com/ljdursi/simple-squiggle-pseudomapper">on github</a>.  It’s written in python, and has <code>scipy</code>, <code>h5py</code>, and <code>matplotlib</code> as dependencies.  Note that as implemented, it is absurdly memory-hungry, and definitely requires a numpy and scipy built against a good BLAS implementation.</p>

<p>As a spatial index, it uses a version of a <a href="https://en.wikipedia.org/wiki/K-d_tree">k-d tree</a> (<code>scipy.spatial.cKDTree</code>), which is a very versatile and widely used (and so well-optimized) spatial index widely used in machine learning methods amongst others; different structures may have advantages for this application.</p>

<p>Running the <code>index-and-map.sh</code> script generates an index for the provided <code>ecoli.fa</code> reference - about 1 minute per pore model - and then maps the 10 reads provided of both older 5mer and newer 6mer MAP data.  Mapping each read takes about 6 seconds per read per pore model; this involves lots of python list manipulations so could fairly straightforwardly be made much faster.<br />
Doing the simplest thing possible for mapping works surprisingly well.  Using the same sort of approach as the first steps of the Sovic <em>et al.</em> method<sup id="fnref:1:1"><a href="#fn:1" class="footnote">1</a></sup>, we just:</p>

<ul>
  <li>Use the default k-d tree parameters (which almost certainly isn’t right, particularly the distance measure)</li>
  <li>Consider overlapping bins of starting positions on the reference, of size ~10,000 events, a typical read size</li>
  <li>For each <script type="math/tex">d</script>-point in the read,
    <ul>
      <li>Take the closest match to each <script type="math/tex">d</script>-point (or all within some distance)</li>
      <li>For each match, add a score to the bin corresponding to the implied starting position of the read on the reference; a higher score for a closer match</li>
    </ul>
  </li>
  <li>Report the best match starting point</li>
</ul>

<p>Let’s take a look at the initial output for the older SQK005 ecoli data and newer SQK006 data:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>./index-and-map.sh

5mer data: 

Indexing : model models/5mer/template.model, dimension 8
python spatialindex.py --dimension 8 ecoli.fa models/5mer/template.model indices/ecoli-5mer-template

real	0m52.922s
user	0m49.756s
sys	0m1.196s
Mapping reads: starting with ecoli/005/LomanLabz_PC_Ecoli_K12_R7.3_2549_1_ch182_file148_strand.fast5
<span class="nb">time </span>python ./mapread.py --plot save --plotdir plots --closest    --maxdist 3.5  <span class="se">\</span>
    --templateindex indices/ecoli-5mer-template.kdtidx    
    ecoli/005/LomanLabz_PC_Ecoli_K12_R7.3_2549_1_ch182_file148_strand.fast5 ...  &gt; template-005-.txt

real	1m9.776s
user	1m9.108s
sys	0m1.004s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch277_file143  819         3079177  3079996  17.164000
ch498_file171  1130        3793866  3794996  11.916000
ch222_file28   1765        2803231  2804996  11.152000
ch461_file9    1895        2195243  2193348  8.749000
ch182_file148  2559        2767555  2764996  17.120000
ch34_file53    4772        1128120  1123348  11.235000
ch401_file98   4981        2328329  2323348  6.160000
ch80_file64    5649        4369347  4374996  7.469000
ch395_file89   5828        2069168  2074996  9.517000
ch464_file15   7031        2195379  2188348  14.782000
Indexing : model models/5mer/complement.model, dimension 8
python spatialindex.py --dimension 8 ecoli.fa models/5mer/complement.model indices/ecoli-5mer-complement

real	0m52.124s
user	0m47.948s
sys	0m1.332s

Mapping reads: starting with ecoli/005/LomanLabz_PC_Ecoli_K12_R7.3_2549_1_ch182_file148_strand.fast5
<span class="nb">time </span>python ./mapread.py --plot save --plotdir plots --closest    --maxdist 3.5  <span class="se">\</span>
    --templateindex indices/ecoli-5mer-template.kdtidx  <span class="se">\</span>
    --complementindex indices/ecoli-5mer-complement.kdtidx <span class="se">\</span>
    ecoli/005/LomanLabz_PC_Ecoli_K12_R7.3_2549_1_ch182_file148_strand.fast5 ...  <span class="se">\</span>
    &gt; template-complement-005-.txt

real	1m47.590s
user	1m46.228s
sys	0m1.712s

Template+Complement Alignements
Read           Difference  BWA      KDTree   zscore
ch401_file98   19          2328329  2328348  7.516000
ch277_file143  819         3079177  3079996  17.164000
ch498_file171  1130        3793866  3794996  11.916000
ch222_file28   1765        2803231  2804996  11.152000
ch461_file9    1895        2195243  2193348  10.378000
ch182_file148  2559        2767555  2764996  17.120000
ch34_file53    4772        1128120  1123348  11.235000
ch80_file64    5649        4369347  4374996  7.469000
ch395_file89   5828        2069168  2074996  9.517000
ch464_file15   7031        2195379  2188348  14.782000

6mer data: 

Indexing : model models/6mer/template.model, dimension 8
python spatialindex.py --dimension 8 ecoli.fa models/6mer/template.model indices/ecoli-6mer-template

real	1m4.028s
user	0m57.924s
sys	0m1.872s

Mapping reads: starting with ecoli/006/LomanLabz_PC_Ecoli_K12_MG1655_20150924_MAP006_1_5005_1_ch102_file146_strand.fast5
<span class="nb">time </span>python ./mapread.py --plot save --plotdir plots --closest --maxdist 3.5 <span class="se">\</span>
    --templateindex indices/ecoli-6mer-template.kdtidx <span class="se">\</span>
    ecoli/006/LomanLabz_PC_Ecoli_K12_MG1655_20150924_MAP006_1_5005_1_ch102_file146_strand.fast5 ...  &gt; template-006-.txt

real	1m46.643s
user	1m45.636s
sys	0m1.276s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch383_file65   844         89152    89996    20.490000
ch209_file0    1119        4564467  4563348  24.038000
ch485_file6    1739        400087   398348   23.698000
ch179_file92   3113        496461   493348   16.477000
ch102_file146  4965        1378313  1373348  25.003000
ch241_file2    5625        1578973  1573348  5.919000
ch339_file119  5710        829058   823348   22.348000
ch412_file79   5806        2194190  2199996  19.218000
ch228_file128  5933        3809063  3814996  17.926000
ch206_file36   11173       4373823  4384996  28.011000

Indexing : model models/6mer/complement_pop1.model, dimension 8
python spatialindex.py --dimension 8 ecoli.fa models/6mer/complement_pop1.model indices/ecoli-6mer-complement_pop1
python spatialindex.py --dimension 8 ecoli.fa models/6mer/complement_pop2.model indices/ecoli-6mer-complement_pop2
<span class="o">[</span>..]

Mapping reads: starting with ecoli/006/LomanLabz_PC_Ecoli_K12_MG1655_20150924_MAP006_1_5005_1_ch102_file146_strand.fast5
<span class="nb">time </span>python ./mapread.py --plot save --plotdir plots --closest --maxdist 3.5  <span class="se">\</span>
    --templateindex indices/ecoli-6mer-template.kdtidx  <span class="se">\</span>
    --complementindex indices/ecoli-6mer-complement_pop1.kdtidx,indices/ecoli-6mer-complement_pop2.kdtidx <span class="se">\</span>
    ecoli/006/LomanLabz_PC_Ecoli_K12_MG1655_20150924_MAP006_1_5005_1_ch102_file146_strand.fast5 ...  &gt; template-complement-006-.txt

real	3m55.773s
user	3m31.032s
sys	0m4.364s

Template+Complement Alignements
Read           Difference  BWA      KDTree   zscore
ch383_file65   844         89152    89996    20.490000
ch209_file0    1119        4564467  4563348  24.038000
ch485_file6    1739        400087   398348   23.698000
ch179_file92   3113        496461   493348   16.477000
ch102_file146  4965        1378313  1373348  25.003000
ch339_file119  5710        829058   823348   22.348000
ch412_file79   5806        2194190  2199996  19.218000
ch228_file128  5933        3809063  3814996  17.926000
ch241_file2    9375        1578973  1588348  11.626000
ch206_file36   11173       4373823  4384996  28.011000</code></pre></div>

<p>We see a couple of things here:</p>

<ul>
  <li>Adding the complement strand does almost nothing for the accuracy,
but requires substantially more memory and compute time, as multiple
indices must be loaded and used up, and all candidate complement
indices must be compared against each other.  Because of this and
the typically higher skip/stay rates for complement strands, we will use the template
strand only for the rest of this post;</li>
  <li>Since we are simply assigning starting bins at this point, 
any assignments within the bin size are equally accurate; here, all
of the reads were correctly assigned to the starting bin or the neighbouring one.</li>
  <li>The newer 6mer data gives slightly better results; part of this
is likely because we are using the same <script type="math/tex">d</script>, so a dmer for the k=6 data
corresponds to seed longer by one</li>
  <li>The zscore here is a very crude measure of how much the assignment
stands out over the background (but not necessarily how it compares
to other candidate mappings); some of these very simple pseudo-mappings 
are relatively securely identified, and others less so.  The sum-of-scores for
the reads with the best and worst zscore results are plotted below; no prize for
guessing which is which:</li>
</ul>

<table>
<tr>
<td> 5mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch277_file143__simple.png" alt="ch277_file143 simple" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch401_file98__simple.png" alt="ch401_file98 simple" style="width: 400px;" /> </td>
</tr>
<tr>
<td> 6mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch206_file36__simple.png" alt="ch206_file36 simple" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch241_file2__simple.png" alt="ch241_file2 simple" style="width: 400px;" /> </td>
</tr>
</table>

<p>Because many levels are clustered near ~60-70pA, many dmers are quite
close to each other, and choosing simply the closest <script type="math/tex">d</script>-point is unlikely
to give a robust result.  Examining all possible matches in the spatial
index within some given radius reduces the noise somewhat, at a modest
increase in compute time:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>./index-and-map.sh noclosest templateonly
5mer data: 
<span class="o">[</span>...]
real	3m15.145s
user	3m5.840s
sys	0m2.972s

Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch401_file98   19          2328329  2328348  11.359000
ch277_file143  819         3079177  3079996  19.103000
ch498_file171  1130        3793866  3794996  15.353000
ch222_file28   1765        2803231  2804996  17.583000
ch182_file148  2559        2767555  2764996  18.579000
ch34_file53    4772        1128120  1123348  16.615000
ch80_file64    5649        4369347  4374996  10.181000
ch395_file89   5828        2069168  2074996  13.145000
ch461_file9    6895        2195243  2188348  10.431000
ch464_file15   7031        2195379  2188348  18.042000

6mer data: 
<span class="o">[</span>...]

real	9m29.562s
user	9m9.536s
sys	0m16.600s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch383_file65   844         89152    89996    21.777000
ch485_file6    1739        400087   398348   24.384000
ch179_file92   3113        496461   493348   19.718000
ch102_file146  4965        1378313  1373348  24.218000
ch241_file2    5625        1578973  1573348  7.311000
ch339_file119  5710        829058   823348   26.045000
ch228_file128  5933        3809063  3814996  20.042000
ch209_file0    6119        4564467  4558348  23.703000
ch412_file79   10806       2194190  2204996  21.677000
ch206_file36   11173       4373823  4384996  29.794000</code></pre></div>

<p>Note the increase in zscores; the same two reads are plotted:</p>

<table>
<tr>
<td> 5mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch277_file143__noclosest.png" alt="ch277_file143 noclosest" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch401_file98__noclosest.png" alt="ch401_file98 noclosest" style="width: 400px;" /> </td>
</tr>
<tr>
<td> 6mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch206_file36__noclosest.png" alt="ch206_file36 noclosest" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch241_file2__noclosest.png" alt="ch241_file2 noclosest" style="width: 400px;" /> </td>
</tr>
</table>

<p>With a few other tweaks - keeping track of the top 10 candidates,
and for each re-testing by recalibrating given the inferred mapping
and rescoring - we can get about 95%-99% accuracy in mapping.</p>

<p><img src="/assets/kdtreemapping/dotplot.png" alt="kd-tree approximate mapping vs BWA MEM mapping positions" /></p>

<p>Of course, while 95-99% (Q13-Q20) mapping accuracy on <em>E. coli</em> is
a cute outcome from such a simple approach, it isn’t nearly
enough; with <script type="math/tex">d=8</script> and <script type="math/tex">k=5</script>, wer’e working with seeds of
size 12, which would typically be unique in the <em>E. coli</em> reference,
but certainly wouldn’t be in the human genome, or for metagenomic
applications.</p>

<h3 id="em-rescaling">EM Rescaling</h3>

<p>One limiting factor is the approximate nature of the rescaling so
far that is being performed; for reads that have been basecalled,
the inferred shift values above can be off by several picoamps from
the Metrichor values, which clearly causes both false negatives and
false positives in the index lookup.  This can be addressed by doing
a more careful rescaling step, using EM iterations:</p>

<ul>
  <li>For the E-step, provisionally assign probabilities of read events
corresponding to model levels, based on the Gaussian distributions 
described in the model and a simple transition matrix between events;</li>
  <li>For the M-step, perform a weighted least squares regression to
re-scale the read levels.</li>
</ul>

<p>This gives answers that are quite good when compared with Metrichor,
at the cost of substantially more computational effort (much greater
than the spatial index lookup!), particularly for long reads and
larger (k) where the number of model levels is larger:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>./index-and-map.sh noclosest templateonly rescale
5mer data: 
<span class="o">[</span>...]
real	7m1.866s
user	6m56.708s
sys	0m29.236s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch401_file98   19          2328329  2328348  14.975000
ch277_file143  819         3079177  3079996  22.516000
ch498_file171  1130        3793866  3794996  20.894000
ch222_file28   1765        2803231  2804996  19.569000
ch182_file148  2559        2767555  2764996  20.443000
ch34_file53    4772        1128120  1123348  17.401000
ch395_file89   5828        2069168  2074996  13.510000
ch461_file9    6895        2195243  2188348  11.165000
ch464_file15   7031        2195379  2188348  19.315000
ch80_file64    10649       4369347  4379996  15.109000

6mer data: 
<span class="o">[</span>...]
real	33m11.324s
user	31m55.172s
sys	2m0.836s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch383_file65   844         89152    89996    23.732000
ch179_file92   3113        496461   493348   20.845000
ch102_file146  4965        1378313  1373348  24.997000
ch241_file2    5625        1578973  1573348  10.574000
ch339_file119  5710        829058   823348   26.816000
ch228_file128  5933        3809063  3814996  21.397000
ch209_file0    6119        4564467  4558348  24.546000
ch485_file6    6739        400087   393348   24.790000
ch412_file79   10806       2194190  2204996  25.477000
ch206_file36   11173       4373823  4384996  30.164000</code></pre></div>

<p>Note again the increase in zscores; replotting gives:</p>

<table>
<tr>
<td> 5mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch277_file143__rescale.png" alt="ch277_file143 rescale" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch401_file98__rescale.png" alt="ch401_file98 rescale" style="width: 400px;" /> </td>
</tr>
<tr>
<td> 6mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch206_file36__rescale.png" alt="ch206_file36 rescale" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch241_file2__rescale.png" alt="ch241_file2 rescale" style="width: 400px;" /> </td>
</tr>
</table>

<h3 id="extending-the-seeds">Extending the seeds</h3>

<p>So far we have in no way taken into account any of the locality
information in the spatial index lookup results; that is, that a long
series of hits close together, in the same order on the read and on the
reference, is much stronger evidence for a good mapping than a haphazard
series of hits in random order that happen to fall within the same bin
of starting points.</p>

<p>Keeping with the do-the-simplest-thing approach that has worked so
far, we can try to extend these “seed” matches by stitching them
together into longer seeds; here we build 15-mers out of sets of 4
neighbouring 12-mers, allowing one skip or stay somewhere within
them, using as a score for the result the minimum of the constituent
scores, and dropping all hits that cannot be so extended.  This has
quite modest additional cost, and works quite well:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>./index-and-map.sh noclosest templateonly rescale extend
5mer data: 

<span class="o">[</span>...]
real	7m20.914s
user	7m19.228s
sys	0m23.620s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch498_file171  1130        3793866  3794996  28.762000
ch222_file28   1765        2803231  2804996  27.434000
ch461_file9    1895        2195243  2193348  29.089000
ch182_file148  2559        2767555  2764996  29.538000
ch34_file53    4772        1128120  1123348  28.837000
ch401_file98   4981        2328329  2323348  23.840000
ch277_file143  5819        3079177  3084996  29.832000
ch395_file89   5828        2069168  2074996  23.705000
ch464_file15   7031        2195379  2188348  28.941000
ch80_file64    10649       4369347  4379996  26.926000

6mer data: 
<span class="o">[</span>...]
real	33m57.863s
user	32m58.236s
sys	1m42.548s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch241_file2    625         1578973  1578348  25.137000
ch485_file6    1739        400087   398348   30.297000
ch339_file119  5710        829058   823348   31.856000
ch383_file65   5844        89152    94996    30.163000
ch228_file128  5933        3809063  3814996  29.294000
ch209_file0    6119        4564467  4558348  30.169000
ch179_file92   8113        496461   488348   28.732000
ch102_file146  9965        1378313  1368348  30.107000
ch412_file79   10806       2194190  2204996  30.377000
ch206_file36   11173       4373823  4384996  33.896000</code></pre></div>

<table>
<tr>
<td> 5mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch277_file143__extend.png" alt="ch277_file143 extend" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch401_file98__extend.png" alt="ch401_file98 extend" style="width: 400px;" /> </td>
</tr>
<tr>
<td> 6mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch206_file36__extend.png" alt="ch206_file36 extend" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch241_file2__extend.png" alt="ch241_file2 extend" style="width: 400px;" /> </td>
</tr>
</table>

<p>Now that we seem to have much stronger and more specific results,
we can investigate letting go of binning, and instead string these
extended seeds into longest possible matches.  Continuing to extend
dmer-by-dmer is too challenging due to missing points (due to
mis-calibration, too large noise in the dmer falling out of the
maxdist window in the kdtree, or several skip/stays in a row), so
following the ideas of graphmap<sup id="fnref:1:2"><a href="#fn:1" class="footnote">1</a></sup> and minimap<sup id="fnref:5:1"><a href="#fn:5" class="footnote">5</a></sup>, we trace
collinear seeds through the set of available seeds; rather than
just taking longest increasing sequences in inferred start positions,
however, we make a graph of seeds with edges connecting  seeds that
are monotonically increasing both in read location and reference
location with ‘small enough’ jumps, and extract longest paths through
this graph.  The cost of this is smaller than the rescaling of the read.</p>

<p>Running this, the zscores now somewhat change meaning; only the extracted
paths are scored, meaning that the scores are only amongst plausible
mappings, not over all bins across the reference.  Similarly, the differences
in mapping locations are somewhat more meaningful - rather than being compared
to bin centres, they are actually the differences between mapping locations.</p>

<p>We get:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">5mer data: 
<span class="o">[</span>...]

real	6m54.776s
user	6m52.064s
sys	0m23.648s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch461_file9    10          2195243  2195253  7.105000
ch34_file53    343         1128120  1128463  12.449000
ch401_file98   363         2328329  2328692  5.320000
ch464_file15   2826        2195379  2192553  13.267000
ch498_file171  3192        3793866  3797058  7.688000
ch182_file148  5450        2767555  2773005  10.107000
ch222_file28   5681        2803231  2808912  8.166000
ch277_file143  6381        3079177  3085558  9.190000
ch395_file89   7191        2069168  2076359  7.685000
ch80_file64    15167       4369347  4384514  7.965000


6mer data: 
<span class="o">[</span>...]

real	43m37.651s
user	42m37.208s
sys	1m42.848s
Template Only Alignments
Read           Difference  BWA      KDTree   zscore
ch209_file0    14          4564467  4564453  31.724000
ch485_file6    14          400087   400073   24.063000
ch241_file2    203         1578973  1578770  26.676000
ch179_file92   723         496461   495738   39.626000
ch339_file119  774         829058   828284   45.636000
ch102_file146  1568        1378313  1376745  45.601000
ch383_file65   5890        89152    95042    27.902000
ch228_file128  8120        3809063  3817183  35.863000
ch412_file79   13833       2194190  2208023  48.444000
ch206_file36   15650       4373823  4389473  38.441000</code></pre></div>

<table>
<tr>
<td> 5mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch277_file143__longest.png" alt="ch277_file143 longest" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch401_file98__longest.png" alt="ch401_file98 longest" style="width: 400px;" /> </td>
</tr>
<tr>
<td> 6mer </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch206_file36__longest.png" alt="ch206_file36 longest" style="width: 400px;" /> </td>
<td> <img src="/assets/kdtreemapping/saveplots/ch241_file2__longest.png" alt="ch241_file2 longest" style="width: 400px;" /> </td>
</tr>
</table>

<p>The simple python testbed implementation of these ideas linked to above
is very slow, single-threaded, absurdly memory hungry, and its treatment
of scores for the mappings does not currently make much sense.  In
the new year we will address these issues in a proper C++ implementation,
where (for instance) we will not have multiple copies of large, reference-sized
data structures.</p>

<hr />

<h3 id="references">References</h3>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="http://biorxiv.org/content/early/2015/06/10/020719">Fast and sensitive mapping of error-prone nanopore sequencing reads with GraphMap</a> (2015) by Sovic, Sikic, Wilm, <em>et al.</em> <a href="#fnref:1" class="reversefootnote">&#8617;</a> <a href="#fnref:1:1" class="reversefootnote">&#8617;<sup>2</sup></a> <a href="#fnref:1:2" class="reversefootnote">&#8617;<sup>3</sup></a></p>
    </li>
    <li id="fn:2">
      <p><a href="http://arxiv.org/abs/1505.02710">Near-optimal RNA-Seq quantification</a> (2015) by Bray, Pimentel, Melsted, and Pachter <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="http://biorxiv.org/content/early/2015/06/27/021592">Salmon: Accurate, Versatile and Ultrafast Quantification from RNA-seq Data using Lightweight-Alignment</a> (2015) by Patro, Duggal, and Kingsford <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://github.com/COMBINE-lab/RapMap">RapMap</a>, COMBINE lab <a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p><a href="http://arxiv.org/abs/1512.01801">Minimap and miniasm: fast mapping and denovo assembly for noisy long sequences</a>, Heng Li <a href="#fnref:5" class="reversefootnote">&#8617;</a> <a href="#fnref:5:1" class="reversefootnote">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>

      </div>
    
  
    
      <div class="post">
        <h1 class="post-title">
          <a href="/2015/10/07/nanopolish-v0.4.0/">
            Nanopolish v0.4.0
          </a>
        </h1>

        <span class="post-date">07 Oct 2015</span>

        <p>This is a long overdue post describing recent changes to <a href="https://github.com/jts/nanopolish">nanopolish</a>.</p>

<h3 id="sqk006-support">SQK006 Support</h3>

<p>Last month Oxford Nanopore released a new sequencing kit, SQK006. As Nick <a href="http://lab.loman.net/2015/09/24/first-sqk-map-006-experiment/">notes</a> there are two important changes that affect how we model the data. Most importantly, ONT changed their basecaller to use 6-mers rather than 5-mers. The relationship between the DNA sequence in the pore and the measured signals is not simple (to understate the problem). By moving to a signal model with longer context the effect of long-range interactions that are not captured by shorter k-mer is hopefully reduced, which may improve read accuracy. In nanopolish v0.4.0 we now support the 6-mer model. This required reworking our data structures to allow either a 5-mer or 6-mer model depending on what sequencing kit was used to generate the data.</p>

<p>SQK006 also brings an increase in speed - from 30bp/s (SQK005) to 70bp/s (SQK006). With the sampling rate fixed to 3kHz we naturally expect more events to be missed by the event detector. We observed this in our analysis of SQK006 data and updated the initial transition probabilities in our HMM accordingly.</p>

<h4 id="sqk006-accuracy">SQK006 Accuracy</h4>

<p>We were quite curious to see how well the new data performs in practice. Nick and Josh made four runs with SQK006 kits - two of native E. coli DNA and two of PCR-treated E. coli DNA to remove DNA damage, base modifications and other artefacts. I downloaded one of the native runs and one of the PCR-treated runs and used it to make a new consensus sequence for the draft assembly in our <a href="http://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3444.html">paper</a>. As before we use dnadiff from <a href="http://mummer.sourceforge.net/">mummer</a> to calculate percent identity, the number of SNPs and the number of indels with respect to the E. coli K12 reference genome.</p>

<table>
  <thead>
    <tr>
      <th>Kit, Coverage</th>
      <th>Percent Identity</th>
      <th># SNPs</th>
      <th># Indels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SQK005, 29X</td>
      <td>99.48%</td>
      <td>1,343</td>
      <td>22,601</td>
    </tr>
    <tr>
      <td>SQK006, 48X</td>
      <td>99.78%</td>
      <td>644</td>
      <td>9,697</td>
    </tr>
    <tr>
      <td>SQK006-PCR, 30X</td>
      <td>99.82%</td>
      <td>222</td>
      <td>8,200</td>
    </tr>
  </tbody>
</table>

<p>The accuracy of our assembly is much better with SQK006 data. Most of this improvement is due to better representation of homopolymer sequences. Interestingly the PCR-treated run gave the best results despite being lower coverage than the native DNA run. It is tempting to attribute this to providing cleaner DNA to the nanopore but this requires further exploration first.</p>

<h3 id="eventalign">Eventalign</h3>

<p>In a previous post I introduced the <a href="http://simpsonlab.github.io/2015/04/08/eventalign/">eventalign</a> submodule, which uses the hidden Markov model to align events to a reference genome. In nanopolish v0.4.0 there are a few eventalign changes and new features. The bulky <code>model_name</code> field has been removed from the output - it bloated the file as every row for a particular read would contain the same information. This read-level information has been moved to a secondary output file which can be enabled with the <code>--summary FILE</code> option. The summary file contains the path to the FAST5 file and model name for each read, along with the number of aligned events and other metadata that may be useful for exploring the alignments.</p>

<h4 id="experimental-sam-output">Experimental SAM output</h4>

<p>eventalign now has an optional <code>--sam</code> flag which will write the alignment in a modified version of the SAM format. By example:</p>

<pre><code>example_2d_read.template    0   chr1    10001   60  9950S4M1I1M2I1M1... *   0   0   *   * ES:i:1
</code></pre>

<p>Most of these fields should be familiar - the alignment contains a read name (annotated with the sequenced strand) followed by flags, a reference name and the alignment start position. Similar to a base-to-base alignment the CIGAR string describes the alignment of events to reference k-mers. <code>9950S4M</code> indicates <code>9950</code> events should be skipped. The next event, <code>9951</code>, aligns to the k-mer starting at reference position <code>10001</code>, followed by three consecutive matches and so on. Sequence and quality information is not stored. The <code>ES</code> auxiliary tag is the <em>event stride</em> - whether the event indices are increasing along the reference sequence (<code>ES:i:1</code>) or whether they are decreasing (<code>ES:i:-1</code>). The nanopolish parser for this format is <a href="https://github.com/jts/nanopolish/blob/master/src/alignment/nanopolish_alignment_db.cpp#L347">here</a>.</p>

<p>There are a few reasons for using this format. First, it is much smaller than the eventalign tsv output. Second, by adopting sam/bam instead of creating a new binary format we can use the existing <code>samtools/htslib</code> ecosystem. Crucially, we can use <code>htslib</code> to provide random access into the alignments for an indexed bam file. This format was developed through discussions with Vadim Zalunin, Ewan Birney, Mick Watson and others. Comments welcome.</p>

      </div>
    
  
    
      <div class="post">
        <h1 class="post-title">
          <a href="/2015/06/15/merging-sv-calls/">
            Merging Structural Variant Calls from Different Callers
          </a>
        </h1>

        <span class="post-date">15 Jun 2015</span>

        <p>As part of the work of the <a href="http://pancancer.info/variant_calling.html">Pancancer variant-calling working
group</a>, we needed to merge the
results of variant calls from a wide range of different packages to compare
their results and select interesting sites for lab validation.  This is a 
more subtle procedure than it sounds, and we could not find any one 
place where all the necessary information was documented, so we wrote up 
our process here.  Code that implements this part of our analysis pipeline
can be found on <a href="https://github.com/ljdursi/mergevcf">GitHub</a>.</p>

<h2 id="simple-variants---snvs-indels">Simple Variants - SNVs, Indels</h2>

<p>The standard format used to output variants is the <a href="http://en.wikipedia.org/wiki/Variant_Call_Format">Variant Call Format</a>.  For <a href="http://en.wikipedia.org/wiki/Single-nucleotide_polymorphism">SNVs</a> and shortish <a href="http://en.wikipedia.org/wiki/Indel">indels</a> (insertions or deletions), this works very well.  Each entry in a VCF file contains the location of the variant (the chromosome it occurs on, and the starting position), the relevant excerpt of the reference sequence starting at that position, and the “alternate” sequence – the variant sequence that has been found there instead.</p>

<p>There are other fields that we will come back to; but a VCF file
containing an A → G SNV at chromosome 1, position 100, a
3 base-pair deletion at chromosome 2, position 200, and a 5 basepair
insertion at chromosome 3, position 300 would look something like this:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#CHROM POS  ID  REF     ALT     ..</span>
1       100 .   A       G   
2       200 .   CGTA    C
3       300 .   T       TACGTA</code></pre></div>

<p>Even this admits some ambiguity; for instance, a deletion of 3 As within a
homopolymer run of 10 of them could reasonably be called at any of 8 positions;
and more complex substitions can be equally described as one large variant, or
as a combination of insertions, deletions, and substitions.  To break these
ambiguities, there is a well understood
<a href="http://genome.sph.umich.edu/wiki/Variant_Normalization">normalization</a>
process, which requires looking at both the reference genome and the VCF file.
It is fairly straightforward, implemented by several
tools, and we perform this step (using <a href="https://samtools.github.io/bcftools/bcftools.html#norm">bcftools
norm</a>) upon
ingesting the submitted calls from various groups.</p>

<p>Once these sorts of calls are normalized, they are fairly easily merged and compared.  We used python for this project, and we used Jared’s code from an earlier pilot for this – using a dictionary of dictionaries, where the first key was a (chromosome,start position) tuple.  The value in the first dictionary corresponding to that key was then a dictionary of (reference allele, variant allele), with a value that was a list of callers that had made that call.  So querying existance of a variant was just two (at most) dictionary lookups; and registering that a caller made a particular call was two dictionary lookups and a list append, possibly creating dictionaries and lists along the way if this was the first time these entries were seen.</p>

<h2 id="structural-variants">Structural Variants</h2>

<p>Performing the same task with structural variants (henceforth SVs) was more complicated for two reasons:</p>

<ol>
  <li>Location - by nature of how SVs are detected, there is quite often uncertainty in the position of called SVs, making comparison more complicated; and</li>
  <li>Description - there are a large number of ways that callers actually call SVs, and they need to be converted to some common representation for comparison.</li>
</ol>

<h3 id="location">Location</h3>

<p>Structural variants are generally observed differently than, say, SNVs.  An alignment-based method might align a read to a reference, find that the alignment unambigiously implies a mismatch, and so call an SNV, as in the top panel of the figure below; there is no question about the location of the variant.   (Obviously, to call the variant with any confidence would require multiple reads, not shown in the figure for clarity.)</p>

<p><img src="/assets/sv/mapping-alpha.png" alt="Mapping SNVs vs SVs" /></p>

<p>However, a structural variant – say a translocation, as in the bottom panel of the figure – will likely be found differently.  In the diagram, paired ends of a read map to two different chromosomes unambigiously, but there is ambiguity as to the location of the two breakpoints on the chromosomes which are now joined to form an new adjacency.   Information from other reads will reduce the uncertainties, even to zero; but in the general case one has to handle ambiguity in location when deciding which calls to merge.</p>

<p>Many callers provided confidence intervals on locations of the breakpoints in their calls, which could be used for constraining the merging of calls.  However, not all callers did; and there was, naturally enough, significant variation in the confidence intervals, even for a given variant.  Thus we took a simpler approach, merging using a fixed window size. Two calls, where each breakpoint of one call was less than the window size away from the corresponding breakpoint of the other call, were merged.</p>

<p>We used a fixed window size of 300bp, of the order of the insert size observed
in the libraries; in principle, this is a more agressive merging strategy than using the confidence intervals when available (which were typically much less), but in practice, there were very few pairs of calls where the larger window size would have mattered.</p>

<p>The most efficient way to look up possible matching locations within some
window would be to use a spatial data structure such as an <a href="http://en.wikipedia.org/wiki/Interval_tree">interval
tree</a>; however, since our window
size was relatively modest, and we are constrained to integer positions, I
dealt with uncertainty in locations in location lookups by brute-force; I
simply search every integer position within the window.  For efficiency, and to
ensure the closest match is found, the search is by distance (pos+0, pos±1, …).  Because dictionary lookup in python is so fast, this approach is “fast enough” for our purposes, in that this is not the rate limiting step for the merging pipeline.</p>

<h3 id="description">Description</h3>

<p>A bigger challenge – not conceptually, but in terms of bookkeeping and corner cases – is simply the diversity of ways in which calls are labelled in VCF files by various callers.</p>

<h4 id="breakpoint-notation-svtypebnd">Breakpoint notation (SVTYPE=BND)</h4>

<p>The <a href="http://samtools.github.io/hts-specs/">VCF Standard</a> describes two ways of describing SVs in a VCF file, of which there are numerous small variations out in the field.  The second, described in somewhat more detail, is breakend notation (usually labelled with an SVTYPE=BND entry in the INFO field of a record).  Before we go into this in much detail, let’s look at a figure describing the possibilties:</p>

<p><img src="/assets/sv/bkpts-alpha.png" alt="VCF Breakpoint meanings" /></p>

<p>To describe a structural variant, we need more than just two positions, one per breakend.  The breakends aren’t just points; they can be thought of as half-intervals, (eg, the piece of Chromosome 1 leading up to position 500; or the piece of Chromsome 1 starting at and continuing from position 500), and we will need that directional information.</p>

<p>(In the VCF spec, from the diagrams it is pretty clear that these are closed intervals; <em>eg</em>, regardless of the direction of the half-interval, the interval includes position 500.  It is not 100% clear to me that every caller that uses BND notation honours that convention, but since we’re using 300-bp windows, such off-by-one errors in location need not concern us here.).</p>

<p>Once that is established, there is one more piece of information which need to be established to define the adjacency between breakends A and B; it can be thought of in two equivalent ways.  One is the relative orientation; is half-interval A joined after half-interval B, or before?   The second is the (relative) strandedness.  Are the two half-intervals joined in such a way that the same strands are joined, or are the strands reversed, as in an inversion?</p>

<p>In VCF BND notation, for consistency with other entries but perhaps somewhat confusingly, only the chromosome and position of the first breakpoint are listed, and then in the ALT field is encoded:</p>

<ul>
  <li>The other chromosome and position of the other breakend (eg, 1:800 in the diagrams above)</li>
  <li>The orientation of the second breakend; whether this is the half-interval which starts at the given position and extends rightwards, <code>[1:800[</code>, or extends from the left and ends at the position given, <code>]1:800]</code>.</li>
  <li>Finally, the relative orientation of the first breakpoint and its direction is specified using the position of other bases relative to the second breakpoint.
    <ul>
      <li>In the examples in the figure, ‘N’ is given in the REF field; the position of that N relative to the <code>]1:800]</code> or <code>[1:800[</code> tells you whether the breakpoint involving 1:500 is joined before or after.</li>
      <li>If after, it is the half-interval including that position and extending rightwards, other it is the breakpoint including that position extending to the left.</li>
      <li>That combined with the relative orientation of the second interval is enough to establish the adjacency.</li>
      <li>The <code>N</code>, of course, could be a real base, if known; and the corresponding bases listed in the ALT field could be one or more different bases, as would be the case if a substitution occurred at or insertion occured between the two half-intervals being joined at the new adjacency.</li>
    </ul>
  </li>
</ul>

<p>Note that the adjacency can be described equally well from either side; that is, for the purposes of identifying the new adjacency we could just as easily list 1:800 first:</p>

<table>
  <thead>
    <tr>
      <th>500 first</th>
      <th>800 first</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>1   500 .   N   N[1:800[</code></td>
      <td><code>1    800 .   N   ]1:500]N</code></td>
    </tr>
    <tr>
      <td><code>1   500 .   N   ]1:800]N</code></td>
      <td><code>1    800 .   N   N[1:500[</code></td>
    </tr>
    <tr>
      <td><code>1   500 .   N   [1:800[N</code></td>
      <td><code>1    800 .   N   [1:500[N</code></td>
    </tr>
    <tr>
      <td><code>1   500 .   N   N]1:800]</code></td>
      <td><code>1    800 .   N   N]1:500]</code></td>
    </tr>
  </tbody>
</table>

<p>When flipping the order of the breakpoints, we either do nothing else (in the case of adjacencies with different relative strandedness/orientation) or also flip position and direction (in the case of adjacencies with the same relative orientation).  Otherwise, we end up describing a different novel adjacency involving the same two positions.</p>

<p>Because we want to merge equivalent adjacencies, and some callers call an adjacency from both sides and others just from one, we normalize the order by always listing the lexicographically first breakpoint position first.</p>

<h4 id="symbolic-notation-translocations-tra">Symbolic Notation Translocations (&lt;TRA&gt;)</h4>

<p>The other way given for describing a structural variant is with “symbolic notation”; listing meaningful tags like &lt;INV&gt; to describe an inversion, or &lt;DUP&gt; to describe a duplication, in the ALT field of a VCF record.</p>

<p>The most general of these is the translocation symbolic call, &lt;TRA&gt;, which isn’t covered in the VCF standard, which essentially works the same way as a BND-style call.  However, since the ALT field is now occupied, we need some other way to put the information about the position of the second breakpoint, and the relative orientation of the two half-intervals.</p>

<p>The other position is listed in the INFO field, with the chromosome given in an entry called CHR2, and the position in an entry called END.   That leaves the relative orientation with which they are joined.</p>

<p>Although again this doesn’t appear to be covered in the VCF specification, the
convention is to use a “connection” field, CT, to indicate whether the 5’ or the 3’ end of the interval involving the first breakpoint position is connected to the 5’ or 3’ end of that involving the second.  This gives the directions of both half-intervals and their connection, which is enough to define the adjacency.</p>

<p>We can then translate between BND notation and translocation calls:</p>

<table>
  <thead>
    <tr>
      <th>BND</th>
      <th>&lt;TRA&gt; with CT INFO field</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>1   500 .   N   N[1:800[</code></td>
      <td><code>1    500 .   N   &lt;TRA&gt;   ... CHR2=1;END=800;CT='3to5'</code></td>
    </tr>
    <tr>
      <td><code>1   500 .   N   ]1:800]N</code></td>
      <td><code>1    500 .   N   &lt;TRA&gt;   ... CHR2=1;END=800;CT='5to3'</code></td>
    </tr>
    <tr>
      <td><code>1   500 .   N   [1:800[N</code></td>
      <td><code>1    500 .   N   &lt;TRA&gt;   ... CHR2=1;END=800;CT='5to5'</code></td>
    </tr>
    <tr>
      <td><code>1   500 .   N   N]1:800]</code></td>
      <td><code>1    500 .   N   &lt;TRA&gt;   ... CHR2=1;END=800;CT='3to3'</code></td>
    </tr>
  </tbody>
</table>

<p>Note again that the adjacencies can be described from either side.  To flip these calls is fairly straightforward; the ends of the intervals (5’ or 3’) belong to their respective breakpoint positions, so flipping the breakpoints just means flipping the positions, and the first and second number in the CT record.  So 3to3 and 5to5 remain the same, while 3to5 becomes 5to3 and vice versa.</p>

<p>Clearly, both <tra> calls and BND-style calls are equivalent; we output BND-style entries for conciseness, but either would work.</tra></p>

<h4 id="higher-level-symbolic-calls-del-inv-dup">Higher-level Symbolic Calls (&lt;DEL&gt;, &lt;INV&gt;, &lt;DUP&gt;)</h4>

<p>Higher-level calls have to be handled a little differently.  Because some
callers may call them using BND-style calls, or even &lt;TRA&gt; calls, they have to be decompose into the lowest common denominator - individual adjacencies.</p>

<p>In the figure below are simple examples of a deletion, an inversion, and a duplication.</p>

<p><img src="/assets/sv/del-inv-alpha.png" alt="VCF Breakpoint meanings" /></p>

<p>The deletion and duplication each generate only one novel adjacency (the 3to5 adjacency between Chr1:10 and Chr1:11 isn’t novel!), wheras the inversion generates 2.</p>

<p>Converting these into BND-style descriptions of the adjacencies follows below.</p>

<table>
  <thead>
    <tr>
      <th>Symbolic Call</th>
      <th>As BND call(s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>1    10 .   N   &lt;DEL&gt;   ... END=20;</code></td>
      <td><code>1	10	.	N	N[1:21[</code></td>
    </tr>
    <tr>
      <td><code>1    10 .   N   &lt;INV&gt;   ... END=20;</code></td>
      <td><code>1	10	.	N	N]1:20]</code></td>
    </tr>
    <tr>
      <td> </td>
      <td><code>1	11	.	N	[1:21[N</code></td>
    </tr>
    <tr>
      <td><code>1    1 .   N   &lt;DUP&gt;   ... END=10;</code></td>
      <td><code>1	1	.	N	]1:10]N</code></td>
    </tr>
  </tbody>
</table>

<p>Breaking up calls like inversions into multiple calls proved important for understanding the comparison of results; we found several cases where some callers called an inversion, whereas others only identified one-half of the event.</p>

<h3 id="complications">Complications</h3>

<p>While the above points cover most of the cases, the rather loose standards in this area cause a number of small bookkeeping headaches.</p>

<p>While callers often specify  CT info fields for symbolic calls, they typically aren’t necessary (and are sometimes inconsistent with the intent of the caller, so suggesting an inverted duplication where a simple duplication is meant, or turning a deletion into a strange translocation, so we strip them out rather than interpreting them.</p>

<p>Similarly, some callers make BND-like calls but use SVCLASS info fields to label the call as a higher-level symbolic call, sometimes then leaving out other information which must then be inferred from the SVCLASS; these then have to be interpreted partly as BND-style calls and partly as symbolic calls.</p>

<h3 id="implementation">Implementation</h3>

<p>We are consider structural variants to be equal for the purposes of merging if they represent a novel adjacency between two “equivalent” breakends.  We do not distinguish between calls that (for instance) have insertions called at the new adjacency.</p>

<p>As with the simple variants, these variants are stored as a python dictionary-of-dictionaries.  Each dictionary is a “locationdict”, taking as a key a (chromosome, position, direction/strand) pair, and querying a key will match any position within the windowsize of that location.  The first key is the (lexicographically first) breakpoint location and direction/strand, and the second is the that of the second.  The final value is a list of callers making the call, and their VCF records for comparison.</p>

<p>By including direction/strand information, we avoid the issue of merging two breakpoints with positions close but indicating opposite half-intervals.  So for instance, in the inversion example above, ]1:20] and [1:21[ are clearly very close together in their starting locations; but they must not be merged, as they are entirely non-overlapping regions.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Identifying common SV calls between two different callers with different conventions for outputting VCF records isn’t a deep algorithmic problem, but lack of consistent documentation makes it more challenging than we had originally anticipated.  We hope that this writeup helps others who are need to do something similar.</p>

      </div>
    
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>

      
      


    </div>
  

  </body>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-61162262-1', 'auto');
  ga('send', 'pageview');

</script>


</html>
